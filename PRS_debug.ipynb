{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from operator import add\n",
    "from math import log\n",
    "import csv\n",
    "import pickle\n",
    "import sys\n",
    "from collections import Counter\n",
    "import re\n",
    "import glob, os\n",
    "\n",
    "import ntpath\n",
    "import functools\n",
    "import itertools\n",
    "\n",
    "from time import time\n",
    "import argparse\n",
    "from PRS_run import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filetype=\"GEN\"\n",
    "\n",
    "# log file\n",
    "snp_log=\"NFP_pruned_nodup_PRS_170116_snplog.csv\"\n",
    "## Setting parameters\n",
    "gwas_id=0   # column of SNP ID\n",
    "gwas_p=1     # column of P value\n",
    "gwas_or=2    # column of odds ratio\n",
    "gwas_a1=3    # column of a1 in the GWAS\n",
    "gwas_a1f=5  # column index of maf in the GWAS\n",
    "\n",
    "# defin column number for contents in genfile\n",
    "if filetype.lower()==\"vcf\":\n",
    "    geno_id= 2 # column number with rsID\n",
    "    geno_start=9 # column number of the 1st genotype, in the raw vcf files, after separated by the delimiter of choice\n",
    "    geno_a1 = 3 # column number that contains the reference allele\n",
    "    GENO_delim= \"\\t\"\n",
    "elif filetype.lower()==\"gen\":\n",
    "    geno_id = 1\n",
    "    geno_start=5\n",
    "    geno_a1=3\n",
    "    GENO_delim=\" \"\n",
    "# List of thresholds:\n",
    "thresholds=[0.5,0.3,0.2,0.1,0.05, 0.01, 0.001, 0.0001]\n",
    "# file delimiters:\n",
    "GWAS_delim=\" \"\n",
    "\n",
    "# Name of GWAS file\n",
    "gwasFiles=\"gwas.cross.txt\"\n",
    "GWAS_has_header=True\n",
    "\n",
    "# programme parameter\n",
    "log_or=True  # sepcify whether you want to log your odds ratios\n",
    "check_ref=True # if you know that there are mismatch between the top strand in the genotypes and that of the GWAS, set True. Not checking the reference allele will improve the speed\n",
    "use_maf=True   # wheather to use MAF to check reference allele\n",
    "\n",
    "# sample file path and name\n",
    "sampleFilePath=\"/scratch/vvp-220-aa/NFP_plink/KieranNFP_0922.sample\" # include the full/relative path and name of the sample file\n",
    "sampleFileDelim=\" \"  # sample File Delimiter\n",
    "sampleFileID=[0]   # which column in the sample file has the ID\n",
    "sample_skip=2 # how many lines to skip so that the sample names can be matched to the genotypes 1-to-1, taking into account the header of the sample file\n",
    "##output file information\n",
    "\n",
    "outputPath=\"NFP_pruned_nodup_PRS_170116.csv\"\n",
    "\n",
    "# Sepcify whether to check for duplicate SNPs\n",
    "checkDup=True\n",
    "\n",
    "\n",
    "# get the name of the genotype files\n",
    "genoFileNamePattern=\"/scratch/vvp-220-aa/NFP/NFP_pruned_nodup.gen\"\n",
    "\n",
    "# get the whole list of the file names\n",
    "genoFileNames=glob.glob(genoFileNamePattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##  start spark context\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "APP_NAME=\"PRS\"\n",
    "\n",
    "spark=SparkSession.builder.appName(APP_NAME).getOrCreate()\n",
    "\n",
    "# if using spark < 2.0.0, use the pyspark module to make Spark context\n",
    "# conf = pyspark.SparkConf().setAppName(APP_NAME).set()#.set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "\n",
    "sc  = spark.sparkContext\n",
    "\n",
    "#sc = spark.sparkContext\n",
    "sc.setLogLevel(\"WARN\")\n",
    "log4jLogger = sc._jvm.org.apache.log4j\n",
    "LOGGER = log4jLogger.LogManager.getLogger(__name__)\n",
    "print(\"Start Reading Files\")\n",
    "print(\"Using these genoytpe files: \")\n",
    "\n",
    "for filename in genoFileNames[:min(24, len(genoFileNames))]:\n",
    "    print(filename)\n",
    "if len(genoFileNames)>23:\n",
    "    print(\"and more...\")\n",
    "\n",
    "print(\"total of {} files\".format(str(len(genoFileNames))))\n",
    "# 1. Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the raw data\n",
    "genodata=sc.textFile(genoFileNamePattern)\n",
    "#print(\"Using the GWAS file: {}\".format(ntpath.basename(gwasFiles)))\n",
    "print(\"Using the GWAS file: {}\".format(gwasFiles))\n",
    "gwastable=spark.read.option(\"header\",GWAS_has_header).option(\"delimiter\", \"\\t\").csv(gwasFiles).cache()\n",
    "print(\"Showing top 5 rows of GWAS file\")\n",
    "gwastable.show(5)\n",
    "\n",
    "print(\"System recognizes the following information in the GWAS :\")\n",
    "print(\"SNP ID : Column {}\".format(gwas_id))\n",
    "print(\"P-values : Column {}\".format(gwas_p))\n",
    "print(\"Effect size : Column {}\".format(gwas_or))\n",
    "print(\"Allele A1 : Column {}\".format(gwas_a1))\n",
    "print(\"Allele A2 : Column {}\".format(gwas_a1+1))\n",
    "if use_maf:\n",
    "    print(\"Allele Frequencies : Column {}\".format(gwas_a1f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1.1 Filter GWAS and prepare odds ratio\n",
    "\n",
    "# filter the genotype to contain only the SNPs less than the maximum p value threshold in the GWAS\n",
    "maxThreshold=max(thresholds)  # maximum p value\n",
    "gwasOddsMapMax=filterGWASByP_DF(GWASdf=gwastable, pcolumn=gwas_p, idcolumn=gwas_id, oddscolumn=gwas_or, pHigh=maxThreshold, logOdds=log_or)\n",
    "gwasOddsMapMaxCA=sc.broadcast(gwasOddsMapMax).value  # Broadcast the map\n",
    "\n",
    "# ### 2. Initial processing\n",
    "# at this step, the genotypes are already filtered to keep only the ones in 'gwasOddsMapMax'\n",
    "bpMap={\"A\":\"T\", \"T\":\"A\", \"C\":\"G\", \"G\":\"C\"}\n",
    "tic=time()\n",
    "if filetype.lower()==\"vcf\":\n",
    "    print(\"Genotype data format : VCF \")\n",
    "\n",
    "    # [chrom, bp, snpid, A1, A2, *genotype]\n",
    "    genointermediate=genodata.filter(lambda line: (\"#\" not in line)).map(lambda line: line.split(GENO_delim)).filter(lambda line: line[geno_id] in gwasOddsMapMaxCA).map(lambda line: line[0:5]+[chunk.split(\":\")[3] for chunk in line[geno_start::]]).map(lambda line: line[0:5]+[triplet.split(\",\") for triplet in line[5::]])\n",
    "\n",
    "    ## (snpid, [genotypes])\n",
    "    genotable=genointermediate.map(lambda line: (line[geno_id], list(itertools.chain.from_iterable(line[5::])))).mapValues(lambda geno: [float(x) for x in geno])\n",
    "    if check_ref:\n",
    "        if use_maf:\n",
    "            print(\"Correcting strand alignment, using MAF\")\n",
    "            genoA1f=genointermediate.map(lambda line: (line[geno_id], (line[geno_a1], line[geno_a1+1]), [float(x) for x in list(itertools.chain.from_iterable(line[5::]))])).map(lambda line: (line[0], line[1][0], line[1][1], getA1f(line[2]))).toDF([\"Snpid_geno\", \"GenoA1\", \"GenoA2\", \"GenoA1f\"])\n",
    "\n",
    "            # 'GwasA1F' means the allele of the A1 frequency in the GWAS\n",
    "            gwasA1f=gwastable.rdd.map(lambda line:(line[gwas_id], line[gwas_a1], line[gwas_a1+1], line[gwas_a1f])).toDF([\"Snpid_gwas\", \"GwasA1\", \"GwasA2\", \"GwasA1F\"])\n",
    "\n",
    "            # checktable = [ geno_snpid, genoA1, genoA2, genoA1f, gwas_snpid, gwasA1, gwasA2, gwasA1f]\n",
    "            checktable=genoA1f.join(gwasA1f, genoA1f[\"Snpid_geno\"]==gwasA1f[\"Snpid_gwas\"], \"inner\").cache()\n",
    "            if checkDup:\n",
    "                flagList = checktable.rdd.map(lambda line: checkAlignmentDF(line, bpMap)).collect()  #  (snpid, flag)\n",
    "                flagMap = rmDup(flagList)\n",
    "            else:\n",
    "                flagMap = checktable.rdd.map(lambda line: checkAlignmentDF(line, bpMap)).collectAsMap()\n",
    "\n",
    "        else:\n",
    "            print(\"Correcting strand alignment, without using MAF\")\n",
    "            genoalleles=genointermediate.map(lambda line: (line[geno_id], (line[geno_a1], line[geno_a1+1]), [float(x) for x in list(itertools.chain.from_iterable(line[5::]))])).map(lambda line: (line[0], line[1][0], line[1][1])).toDF([\"Snpid_geno\", \"GenoA1\", \"GenoA2\"])\n",
    "\n",
    "            gwasalleles=gwastable.rdd.map(lambda line:(line[gwas_id], line[gwas_a1], line[gwas_a1+1])).toDF([\"Snpid_gwas\", \"GwasA1\", \"GwasA2\"])\n",
    "\n",
    "            checktable=genoalleles.join(gwasalleles, genoalleles[\"Snpid_geno\"]==gwasalleles[\"Snpid_gwas\"], \"inner\").cache()\n",
    "\n",
    "            if checkDup:\n",
    "                flagList = checktable.rdd.map(lambda line: checkAlignmentDFnoMAF(line, bpMap)).collect()\n",
    "                flagMap = rmDup(flagList)\n",
    "            else:\n",
    "                # no need to check the duplicates if the data is preprocessed\n",
    "                flagMap = checktable.rdd.map(lambda line: checkAlignmentDFnoMAF(line, bpMap)).collectAsMap()\n",
    "\n",
    "        print(\"Generating genotype dosage while taking into account difference in strand alignment\")\n",
    "        flagMap=sc.broadcast(flagMap).value\n",
    "        genotypeMax=genotable.filter(lambda line: line[0] in flagMap and flagMap[line[0]]!=\"discard\").map(lambda line: makeGenotypeCheckRef(line, checkMap=flagMap)).cache()\n",
    "\n",
    "    else:\n",
    "        print(\"Generating genotype dosage without checking reference allele alignments\")\n",
    "        genotypeMax=genotable.mapValues(lambda line: makeGenotype(line)).cache()\n",
    "        if checkDup:\n",
    "            genotypeCount=genotypeMax.map(lambda line: (line[0], 1)).reduceByKey(lambda a,b: a+b).filter(lambda line: line[1]==1).collectAsMap()\n",
    "            genotypeMax=genotypeMax.filter(lambda line: line[0] in genotypeCount)\n",
    "\n",
    "elif filetype.lower() == \"gen\":\n",
    "    print(\"Genotype data format : GEN\")\n",
    "    genotable=genodata.map(lambda line: line.split(GENO_delim)).filter(lambda line: line[geno_id] in gwasOddsMapMaxCA).map(lambda line: (line[geno_id], line[geno_start::])).mapValues(lambda geno: [float(call) for call in geno])\n",
    "    if check_ref:\n",
    "        if use_maf:\n",
    "            print(\"Correcting strand alignment, using MAF\")\n",
    "            genoA1f=genodata.map(lambda line: line.split(GENO_delim)).map(lambda line: (line[geno_id], line[geno_a1], line[geno_a1+1], getA1f([float(x) for x in line[geno_start::]]))).toDF([\"Snpid_geno\", \"GenoA1\", \"GenoA2\", \"GenoA1f\"])\n",
    "            gwasA1f=gwastable.rdd.map(lambda line:(line[gwas_id], line[gwas_a1], line[gwas_a1+1], line[gwas_a1f])).toDF([\"Snpid_gwas\", \"GwasA1\", \"GwasA2\", \"GwasA1f\" ])\n",
    "            checktable=genoA1f.join(gwasA1f, genoA1f[\"Snpid_geno\"]==gwasA1f[\"Snpid_gwas\"], \"inner\").cache()\n",
    "            if checkDup:\n",
    "                print(\"Searching and removing duplicated SNPs\")\n",
    "                flagList = checktable.rdd.map(lambda line: checkAlignmentDF(line, bpMap)).collect()\n",
    "                flagMap = rmDup(flagList)\n",
    "            else:\n",
    "                flagMap = checktable.rdd.map(lambda line: checkAlignmentDF(line, bpMap)).collectAsMap()\n",
    "        else:\n",
    "            print(\"Correcting strand alignment, without using MAF\")\n",
    "            genoalleles=genodata.map(lambda line: line.split(GENO_delim)).map(lambda line: (line[geno_id], line[geno_a1], line[geno_a1+1])).toDF([\"Snpid_geno\", \"GenoA1\", \"GenoA2\"])\n",
    "            gwasalleles=gwastable.rdd.map(lambda line:(line[gwas_id], line[gwas_a1], line[gwas_a1+1])).toDF([\"Snpid_gwas\", \"GwasA1\", \"GwasA2\"])\n",
    "            checktable=genoalleles.join(gwasalleles, genoalleles[\"Snpid_geno\"]==gwasalleles[\"Snpid_gwas\"], \"inner\").cache()\n",
    "\n",
    "            if checkDup:\n",
    "                print(\"Searching and removing duplicated SNPs\")\n",
    "                flagList = checktable.rdd.map(lambda line: checkAlignmentDFnoMAF(line, bpMap)).collect()\n",
    "                flagMap = rmDup(flagList)\n",
    "            else:\n",
    "                flagMap = checktable.rdd.map(lambda line: checkAlignmentDFnoMAF(line, bpMap)).collectAsMap()\n",
    "\n",
    "        print(\"Generating genotype dosage while taking into account difference in strand alignment\")\n",
    "        flagMap=sc.broadcast(flagMap).value\n",
    "        genotypeMax=genotable.filter(lambda line: line[0] in flagMap and flagMap[line[0]]!=\"discard\" ).map(lambda line: makeGenotypeCheckRef(line, checkMap=flagMap)).cache()\n",
    "\n",
    "    else:\n",
    "        print(\"Generating genotype dosage without checking strand alignments\")\n",
    "        genotypeMax=genotable.mapValues(lambda line: makeGenotype(line)).cache()\n",
    "        if checkDup:\n",
    "            genotypeCount=genotypeMax.map(lambda line: (line[0], 1)).reduceByKey(lambda a,b: a+b).filter(lambda line: line[1]==1).collectAsMap()\n",
    "            genotypeMax=genotypeMax.filter(lambda line: line[0] in genotypeCount)\n",
    "\n",
    "print(\"Dosage generated in {:f} seconds\".format(time()-tic) )\n",
    "samplesize=int(len(genotypeMax.first()[1]))\n",
    "print(\"Detected {} samples\" .format(str(samplesize)))\n",
    "\n",
    "#genoa1f.map(lambda line:\"\\t\".join([line[0], \"\\t\".join(line[1]), str(line[2])])).saveAsTextFile(\"../MOMS_info03_maf\")\n",
    "\n",
    "# Calculate PRS at the sepcified thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcPRSFromGeno(genotypeRDD, oddsMap):\n",
    "    totalcount=genotypeRDD.count()\n",
    "    multiplied=genotypeRDD.map(lambda line:[call * oddsMap[line[0]] for call in line[1]])\n",
    "    PRS=multiplied.reduce(lambda a,b: map(add, a, b))\n",
    "    normalizedPRS=[x/totalcount for x in PRS]\n",
    "    return (totalcount,PRS)\n",
    "\n",
    "def calcAll(genotypeRDD, gwasRDD, thresholdlist, logsnp):\n",
    "    prsMap={}\n",
    "    thresholdNoMaxSorted=sorted(thresholdlist, reverse=True)\n",
    "\n",
    "    thresholdmax=max(thresholdlist)\n",
    "    idlog={}\n",
    "    start=time()\n",
    "    for threshold in thresholdNoMaxSorted:\n",
    "        tic=time()\n",
    "        gwasFilteredBC=sc.broadcast(filterGWASByP_DF(GWASdf=gwasRDD, pcolumn=gwas_p, idcolumn=gwas_id, oddscolumn=gwas_or, pHigh=threshold, logOdds=log_or))\n",
    "        #gwasFiltered=spark.sql(\"SELECT snpid, gwas_or_float FROM gwastable WHERE gwas_p_float < {:f}\".format(threshold)\n",
    "        print(\"Filtered GWAS at threshold of {}. Time spent : {:f} seconds\".format(str(threshold), time()-tic))\n",
    "        checkpoint=time()\n",
    "        filteredgenotype=genotypeRDD.filter(lambda line: line[0] in gwasFilteredBC.value)\n",
    "\n",
    "        if not filteredgenotype.isEmpty():\n",
    "            if logsnp:\n",
    "                idlog[threshold]=filteredgenotype.map(lambda line:line[0]).collect()\n",
    "            prsMap[threshold]=calcPRSFromGeno(filteredgenotype, gwasFilteredBC.value)\n",
    "\n",
    "            print(\"Finished calculating PRS at threshold of {}. Time spent : {:f} seconds\".format(str(threshold), time()-checkpoint))\n",
    "    return prsMap, idlog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prsDict, snpids=calcAll(genotypeMax,gwastable, thresholds, logsnp=snp_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# log which SNPs are used in PRS\n",
    "if snp_log:\n",
    "    logoutput=writeSNPlog(snpids, snp_log)\n",
    "# generate labels for samples\n",
    "#if filetype.lower()==\"vcf\":\n",
    "    #subjNames=genodata.filter(lambda line: \"#CHROM\" in line).map(lambda line: line.split(GENO_delim)[9::]).collect()[0]\n",
    "    #output=writePRS(prsDict,  outputPath, samplenames=subjNames)\n",
    "\n",
    "if sampleFilePath!=\"NOSAMPLE\":\n",
    "    # get sample name from the provided sample file\n",
    "    subjNames=getSampleNames(sampleFilePath,sampleFileDelim,sampleFileID, skip=sample_skip)\n",
    "    print(\"Extracted {} sample labels\".format(len(subjNames[0])))\n",
    "    output=writePRS(prsDict,  outputPath, samplenames=subjNames)\n",
    "else:\n",
    "    print(\"No sample file detected, generating labels for samples.\")\n",
    "    output=writePRS(prsDict,  outputPath, samplenames=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CQ - Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
